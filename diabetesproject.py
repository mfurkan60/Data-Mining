# -*- coding: utf-8 -*-
"""DiabetesProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HrMI5DK8HxCFLZ_YYBzU-vLkH_QQSxp-

#Data Mining Project

##Libraries
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier

"""##Editing Data"""

#We called our dataset and visualized it with the data.head() command.
data = pd.read_csv("diabetes.csv")
data.head()

#We decided whether it is true or false by looking at the types in the data set.
data.info()

#we looked for empty data, lost data.
data.isna().sum()

#Values ​​like glucose,bloodpressure etc. can not be 0, we have to regulate them.
data.eq(0).sum()

#Missing Data Imputation Using Regression


def ImputeZeroValuesWithRegression(dataset):

  columnsToBeImputed = ['Glucose','Insulin','SkinThickness','BMI']
  for column in columnsToBeImputed:

    test_df = dataset[dataset[column]==0]


    y_train= dataset[column]
    x_train= dataset.drop(column,axis=1)

    X_test = test_df.drop(column, axis=1)

    lr=LinearRegression()
    lr.fit(x_train,y_train)
    y_pred=lr.predict(X_test)


    dataset.loc[dataset[column]==0,column] = y_pred

  return dataset
df=ImputeZeroValuesWithRegression(dataset=data)

df

"""##Classification Task:Logistic Regression"""

#creation of algorithms.
x=data[['Glucose', 'BMI', 'Age', 'Pregnancies', 'SkinThickness',
       'Insulin', 'DiabetesPedigreeFunction']]
y=data.iloc[:,8]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.10,random_state=0)

#log reg.
log_reg = LogisticRegression(random_state=1, max_iter=100).fit(x_train, y_train)
predict=log_reg.predict(x_test)

#predict for Logistic Reg.
predict

print("Logistic Regression Classifier Training Accuracy: ",log_reg.score(x_test,y_test))

"""##Classification Task:Random Forest"""

#randomforest
forest=RandomForestClassifier(n_estimators=20,criterion="entropy",random_state=0)
forest.fit(x_train,y_train)

#predict for forest classifier.
y_pred=forest.predict(x_test)
predict

print("Random Forest Classifier Training Accuracy: ",forest.score(x_test,y_test))

"""##Classification Task:KNN Classifier"""

#knn
KNN=KNeighborsClassifier(n_neighbors=1)
KNN.fit(x_train,y_train)

#predict for KNN.
y_pred=KNN.predict(x_test)

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))

print("KNN classifier training accuracy: ",KNN.score(x_test,y_test))